ORDER OF GROWTH:

The order of growth, also known as time complexity or computational complexity, is a measure of how the performance of an algorithm scales with the input size. In the context of data structures, the order of growth refers to the efficiency of various operations performed on the data structure.

Here are the commonly used orders of growth in data structures:

O(1) - Constant Time: Operations that have a constant time complexity are considered the most efficient. It means that the execution time of an operation remains constant, regardless of the input size. Examples include accessing an element in an array by index or inserting an element at the beginning of a linked list.

O(log n) - Logarithmic Time: Operations that have logarithmic time complexity typically involve dividing the input size in half at each step. These operations are commonly found in balanced search trees, such as AVL trees or red-black trees. Searching or inserting elements in such data structures takes logarithmic time.

O(n) - Linear Time: Operations that have linear time complexity have a runtime proportional to the input size. For example, traversing a linked list or an array requires visiting each element once, resulting in linear time complexity.

O(n log n) - Linearithmic Time: Operations that have linearithmic time complexity often arise in efficient sorting algorithms like Merge Sort or Heap Sort. The runtime grows linearly with the input size, multiplied by the logarithm of the input size.

O(n^2) - Quadratic Time: Operations with quadratic time complexity scale with the square of the input size. Nested loops are a common cause of quadratic time complexity. For example, a simple bubble sort or a selection sort algorithm exhibits quadratic time complexity.

O(2^n) - Exponential Time: Operations that have exponential time complexity are highly inefficient. The execution time grows exponentially with the input size. Recursive algorithms that solve problems through exhaustive search or brute force often fall into this category.

The time taken : O(1)< O(logn) < O(n) < O(n logn) < O(n^2) < O(2^n)